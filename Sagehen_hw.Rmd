---
title: "Sagehen_HW"
output: html_document
date: "2024-04-25"
---
# Part 1: Come up with a combined metric that you think is interesting 

* if you can, try to include at least one metric (as part of your combined metric) that needs to be transformed be creative
* you can subset, aggregate, focus only on particular type of years or days    
* think about ecological or human water uses that depend on certain flow conditions   

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sensitivity)
library(tidyverse)
library(purrr)
library(ggpubr)
```

# Comparing model and observed time series output
```{r simple}
sager = read.table("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/ESM232_Examples_S24/Data/sager.txt", header=T)
head(sager)

# add date
sager = sager %>% mutate(date = paste(day,month,year, sep="/"))
sager$date = as.Date(sager$date,"%d/%m/%Y")

# plot
sagerl = sager %>% pivot_longer(cols=c("model","obs"), names_to="source",
                                  values_to="flow")

# basic plot
ggplot(sagerl, aes(date, flow, col=source, linetype=source))+geom_line()
```


```{r simple2}
# change axis to get a closer look at performance at low values
# when you have high dynamic range (lots of large and small values), taking log can help
# with visualization
ggplot(sagerl, aes(date, flow, col=source, linetype=source))+geom_line()+scale_y_continuous(trans="log")+labs(y="streamflow mm/day")
```


```{r simple3}
# look at it another way
ggplot(sager, aes(obs, model))+geom_point()+geom_abline(intercept=0, slope=1, col="red")

```

# Measure Performance using different metrics

```{r}
source("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/homework/sagehen_hw_apr25/calibrate_sagehen_streamflow/combined_metrics_K.R")

#(m=sager$model, o=sager$obs)
#source("../R/nse.R")

source("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/homework/sagehen_hw_apr25/calibrate_sagehen_streamflow/nse.R")
#source("../R/relerr.R")
source("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/homework/sagehen_hw_apr25/calibrate_sagehen_streamflow/relerr.R")

#source("../R/cper.R")
source("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/homework/sagehen_hw_apr25/calibrate_sagehen_streamflow/cper.R")

nse(m=sager$model, o=sager$obs)

relerr(m=sager$model, o=sager$obs)*100

cper(m=sager$model, o=sager$obs, weight.nse=0.8)

combined_function(m=sager$model,o=sager$obs, weight.nse=0.33, weight.rmse=0.33, weight.relerr=0.34)
```

# Scale and subsetting

Performance also depends on the 'what' you are evaluating

  * time steps (annual, daily, monthly)
  * selection of particular periods of time

# We decided to subset for rainy season, which is known to be between Nov. 1 and March 31. in California; rainy season brings higher flow-rate 
```{r}

# # look at rainy season, Nov to March
# sager_filtered <- sager %>% 
#   filter(month %in% c(11, 12, 1, 2, 3)) %>%
#   group_by(month, year) %>%
#   summarize(model = sum(model), obs = sum(obs))

# turn your evaluation metric into a function
source("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/homework/sagehen_hw_apr25/calibrate_sagehen_streamflow/high_flow_K.R")
# use different high flow months
#change from august to Nov - March
high_flow_metrics_K(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, high_flow_months = c(11:3))

```
  
# Create a combined metric

Sometime you want to summarize everything in one number especially if you want to rank different models or create indices like Sobol Sensitivity Indices

```{r}
#see combined_function
combined_function(m=sager$model,o=sager$obs, weight.nse=0.33, weight.rmse=0.33, weight.relerr=0.34)

```

# Part II

Calibration is picking parameter sets based on performance evaluation

Apply metrics over multiple outputs (generated by running across many parameters sets) 

Ideally we'd generate these parameter "smartly" - LHS or Sobol sampling

Example - a dataset where each column is a different model run for Sagehen Creek (using different parameters) don't worry about what theparameters are for now

File Name
* sagerm.txt

Perform a split-sample calibration on the Sagehen model output (sagerm.txt) 
you can decide what years to pick for pre and post calibration
use your performance metric from Part I

```{r}
# performance metric is: perf

# multiple results - lets say we've run the model for multiple years, each column
# is streamflow for a different parameter set
msage = read.table("~/Documents/2_Areas/Areas_MEDS/Spring_Quarter/EDS230_Env_mod/ESM232_Examples_S24/Data/sagerm.txt", header=T)


msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy


# Transform data for analysis
msagel <- msage %>% pivot_longer(cols =!c(date, month, year, day, wy), names_to = "run", values_to = "flow")

# Split the data into pre and post calibration years; pre_calibration is 1960 to 1970; post is 1980 to 1990 
pre_calibration <- subset(msage, wy >= 1970 & wy <= 1979) #subset for year between 1960 and 1969 #training dataset 
post_calibration <- subset(msage, wy >= 1980 & wy <= 1989) #subset for year between 1980 and 1989  #validation dataset 

##check out the pre_calibration graph
pre_calibration_graph=ggplot(subset(msagel, wy >= 1970 & wy <= 1979), aes(as.Date(date), flow, col=run))+geom_line()+theme(legend.position = "none")

# lets add observed streamflow
pre_calibration_graph+geom_line(data=subset(sager,  wy >= 1970 & wy <= 1979), aes(as.Date(date), obs), size=2, col="black", linetype=2)+labs(y="Streamflow", x="Date")


#res = msage %>% select(!c("date","month","year","day","wy")) %>%
#      map_dbl(nse, o=sager$obs )

# using our high flow statistics use apply to compute for all the data using the updated flow metrics routing that also computed combined metrics

res = pre_calibration %>% select(!c("date","month","year","day","wy")) %>% map_df(combined_function, o=sager$obs)

resl = res %>% pivot_longer(cols = starts_with("V"), names_to="run", values_to="value") 


```


Find the best and worst parameter set, given your performance metric

```{r}

# extract best and worst runs
best_run <- resl[which.max(resl$value), ]
worst_run <-  resl[which.min(resl$value), ]

paste("Best run V_num:", best_run$run, " Best run value:", best_run$value)
paste("Worst run V_num:", worst_run$run, " Worst run value:", worst_run$value)
```

# validation step -- run the model with these parameters from V127 on 1980-1989 data? 




Graph something about streamflow (e.g daily, mean August, or ?) for the best parameter set *

```{r}
#the best parameter set for this performance metric was V130; 

ggplot(subset(msagel, run == "V130"), aes(x= date, flow)) + 
  geom_line() +
  labs(x = "Date", y = "Flow (mm/month)", title = "Monthly Aggregate Maximum Stream Flow for best model run") + theme_minimal()

```


Compute and plot how the performance of the model using the best parameter set changed in pre and post calibration periods (that you chose)


```{r}

```


Add the 'best' parameter set column number  to the quiz linked below (so we can compare how different metrics influence which parameter you pick) 

```{r}

```

Write 2-3 sentences to explain your metric design and comment on model performance based on your metric
